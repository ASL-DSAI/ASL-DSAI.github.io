<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Autonomous Simulations Lab â€“ Data Science & AI, IIT Madras</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            background: #f9f9f9;
            color: #333;
            line-height: 1.6;
        }
        header {
            background: #002147;
            color: white;
            text-align: center;
            padding: 30px 20px;
        }
        header img {
            max-width: 120px;
            height: auto;
            vertical-align: middle;
        }
        header h1 {
            margin: 10px 0 0;
            font-size: 2.2em;
        }
        main {
            max-width: 900px;
            margin: 40px auto;
            padding: 0 20px;
            background: white;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        .intro {
            padding: 30px 0;
        }
        .intro p {
            font-size: 1.1em;
        }
        .section {
            margin-bottom: 40px;
        }
        .section h2 {
            color: #002147;
            border-bottom: 3px solid #002147;
            padding-bottom: 6px;
            margin-bottom: 16px;
        }
        .section ul {
            margin-left: 20px;
        }
        
        /* Paper Presentation Section Styles */
        .paper-presentation {
            background: #f0f7ff;
            padding: 25px;
            border-radius: 8px;
            margin-bottom: 40px;
            border-left: 5px solid #002147;
        }
        .paper-presentation h2 {
            color: #002147;
            margin-top: 0;
        }
        .video-container {
            position: relative;
            width: 100%;
            height: 0;
            padding-bottom: 56.25%; /* 16:9 aspect ratio */
            margin: 20px 0;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
            border-radius: 4px;
            overflow: hidden;
            background: #002147;
        }
        .video-container video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
        .video-placeholder {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            color: white;
            text-align: center;
            padding: 20px;
        }
        .video-placeholder .icon {
            font-size: 48px;
            margin-bottom: 15px;
        }
        .paper-info {
            background: white;
            padding: 20px;
            border-radius: 6px;
            margin-top: 20px;
            box-shadow: 0 2px 6px rgba(0,0,0,0.05);
        }
        .paper-title {
            font-size: 1.3em;
            font-weight: bold;
            color: #002147;
            margin-bottom: 15px;
        }
        .paper-authors {
            font-style: italic;
            margin-bottom: 15px;
        }
        .paper-abstract {
            margin-bottom: 15px;
            text-align: justify;
        }
        .paper-keywords {
            font-size: 0.9em;
            color: #666;
        }
        .paper-keywords span {
            font-weight: bold;
        }
        .paper-citation {
            font-size: 0.85em;
            color: #555;
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px dashed #ccc;
        }
        .research-platform {
            background: #e8f5e9;
            padding: 15px;
            border-radius: 6px;
            margin-top: 20px;
            border-left: 4px solid #4caf50;
        }
        .research-platform a {
            color: #002147;
            font-weight: bold;
            text-decoration: none;
        }
        .research-platform a:hover {
            text-decoration: underline;
        }
        .video-format-notice {
            background: #fff3cd;
            padding: 10px 15px;
            border-radius: 4px;
            margin-top: 10px;
            font-size: 0.9em;
            border-left: 4px solid #ffc107;
        }
        
        footer {
            text-align: center;
            padding: 20px;
            background: #eee;
            color: #666;
            font-size: 0.9em;
        }
        
        @media (max-width:600px) {
            header h1 {
                font-size: 1.6em;
            }
            main {
                margin: 20px auto;
            }
            .paper-presentation {
                padding: 15px;
            }
        }
    </style>
</head>
<body>
    <header>
        <img src="logo.png" alt="Lab Logo â€“ IIT Madras">
        <h1>Autonomous Simulations Lab<br>Data Science &amp; AI, IIT Madras</h1>
    </header>
    
    <main>
        <div class="intro">
            <p>Welcome to the <strong>Autonomous Simulations Lab</strong> at IIT Madras, operating within the Data Science &amp; AI research domain. We pioneer simulation-based engineering, autonomous systems, and data-driven modelling for real-world complex problems.</p>
        </div>
        
        <!-- Paper Presentation Section -->
        <div class="paper-presentation">
            <h2>Featured Paper Presentation</h2>
            <div class="video-container">
                <video controls poster="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='800' height='450' viewBox='0 0 800 450'%3E%3Crect width='800' height='450' fill='%23002147'/%3E%3Ctext x='50%25' y='50%25' dominant-baseline='middle' text-anchor='middle' font-family='Arial' font-size='24' fill='white'%3EPIELM Paper Presentation%3C/text%3E%3C/svg%3E">
                    <!-- Try MOV format first -->
                    <source src="https://raw.githubusercontent.com/yourusername/yourrepository/main/assets/presentation_b8a3e179-eec1-41e3-bb7c-d896ca1047f2.mov" type="video/quicktime">
                    <!-- Fallback to MP4 if MOV doesn't work -->
                    <source src="https://raw.githubusercontent.com/yourusername/yourrepository/main/assets/presentation_b8a3e179-eec1-41e3-bb7c-d896ca1047f2.mp4" type="video/mp4">
                    <!-- Fallback message -->
                    <div class="video-placeholder">
                        <div class="icon">ðŸ“¹</div>
                        <p>Your browser doesn't support the video tag or the video format.</p>
                        <p><a href="https://raw.githubusercontent.com/yourusername/yourrepository/main/assets/presentation_b8a3e179-eec1-41e3-bb7c-d896ca1047f2.mov" style="color: white; text-decoration: underline;">Download the video instead</a></p>
                    </div>
                </video>
            </div>
            
            <div class="video-format-notice">
                <strong>Note:</strong> If the video doesn't play, try downloading it directly using the link above. MOV format videos may require QuickTime player on some devices.
            </div>
            
            <div class="research-platform">
                <p><strong>Video Generation Platform:</strong> This presentation was generated using <a href="http://saral.democratiseresearch.in" target="_blank">Saral - Democratise Research</a>, an innovative platform for creating research presentations.</p>
            </div>
            
            <div class="paper-info">
                <div class="paper-title">
                    Physics Informed Extreme Learning Machine (PIELM) â€“ A rapid method for the numerical solution of partial differential equations
                </div>
                
                <div class="paper-authors">
                    Vikas Dwivedi*, Balaji Srinivasan
                </div>
                
                <div class="paper-abstract">
                    <strong>Abstract:</strong> There has been rapid progress recently on the application of deep networks to the solution of partial differential equations, collectively labeled as Physics Informed Neural Networks (PINNs). In this paper, We develop Physics Informed Extreme Learning Machine (PIELM), a rapid version of PINNs which can be applied to stationary and time-dependent linear partial differential equations. We demonstrate that PIELM matches or exceeds the accuracy of PINNs on a range of problems. We also discuss the limitations of neural network-based approaches, including our PIELM, in the solution of PDEs on large domains and suggest an extension, a distributed version of our algorithm â€“ DPIELM. We show that DPIELM produces excellent results comparable to conventional numerical techniques in the solution of time-dependent problems. Collectively, this work contributes towards making the use of neural networks in the solution of partial differential equations in complex domains as a competitive alternative to conventional discretization techniques.
                </div>
                
                <div class="paper-keywords">
                    <span>Keywords:</span> Partial differential equations, Physics informed neural networks, Extreme learning machine, Advection-Diffusion equation
                </div>
                
                <div class="paper-citation">
                    <strong>Citation:</strong> Vikas Dwivedi, Balaji Srinivasan, Physics Informed Extreme Learning Machine (PIELM) â€“ A rapid method for the numerical solution of partial differential equations, 2020, Elsevier B.V.
                </div>
            </div>
        </div>
        
        <div class="section">
            <h2>Our Vision</h2>
            <p>To lead in the integration of high-fidelity simulation environments, AI-driven automation, and robust autonomous system design â€” enabling next-generation solutions for robotics, mobility, and multi-agent systems in real-world scenarios.</p>
        </div>
        
        <div class="section">
            <h2>Our Papers</h2>
            <ul>
                <li>Paper 1: [Title] â€” A study on automating simulation workflows using AI-augmented methods.</li>
                <li>Paper 2: [Title] â€” Development of multi-agent simulation frameworks for autonomous navigation in complex environments.</li>
                <li>Paper 3: [Title] â€” Data-driven modeling and verification of autonomous systems in high-fidelity simulation.</li>
            </ul>
        </div>
        
        <div class="section">
            <h2>Our Projects</h2>
            <ul>
                <li>Project A: Autonomous navigation in cluttered indoor/outdoor environments â€” designing simulation architectures and control algorithms.</li>
                <li>Project B: Multi-agent coordination and emergent behaviour modelling in simulated robotics ecosystems.</li>
                <li>Project C: AI-assisted generation of simulation workflows â€” coupling numerical solvers with natural-language driven automation.</li>
            </ul>
        </div>
        
        <div class="section">
            <h2>Contact &amp; Collaboration</h2>
            <p><strong>Prof. Balaji Srinivasan</strong><br> E-mail: <a href="mailto:sbalaji@dsai.iitm.ac.in">sbalaji@dsai.iitm.ac.in</a></p>
            <p>Department of Engineering Design, IIT Madras, Chennai 600036, Tamil Nadu, India</p>
        </div>
    </main>
    
    <footer>
        &copy; 2025 Autonomous Simulations Lab, IIT Madras. All rights reserved.
    </footer>

    <script>
        // JavaScript to handle video loading issues
        document.addEventListener('DOMContentLoaded', function() {
            const video = document.querySelector('video');
            const videoSources = video.querySelectorAll('source');
            let currentSourceIndex = 0;
            
            // If first source fails, try the next one
            video.addEventListener('error', function() {
                if (currentSourceIndex < videoSources.length - 1) {
                    currentSourceIndex++;
                    video.src = videoSources[currentSourceIndex].src;
                    video.load();
                } else {
                    console.log('All video sources failed to load');
                }
            }, true);
            
            // Show custom message if video can't play
            video.addEventListener('canplaythrough', function() {
                console.log('Video can play through');
            });
        });
    </script>
</body>
</html>
